{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_TRACING_v2\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"tutorial\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import utils\n",
    "utils.tracing_is_enabled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(model=os.getenv(\"LLM_MODEL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_db_retrieval():\n",
    "    with open(\"../prompts/polly_facts.txt\", \"r\") as f:\n",
    "        poly_facts = f.read()\n",
    "    return poly_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You want to know what sport I'm the best at?\\n\\nI'd say that playing soccer is my strong suit! I love running around with my beak and wings, chasing after the ball and scoring goals. It's such a thrill!\\n\\n(By the way, can someone please pass me an animal cracker? I had one before our chat started, but now I'm craving another!)\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-03-03T10:09:27.069548487Z', 'done': True, 'done_reason': 'stop', 'total_duration': 398369666, 'load_duration': 20663451, 'prompt_eval_count': 113, 'prompt_eval_duration': 6000000, 'eval_count': 78, 'eval_duration': 369000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-48f92b29-bd53-489b-8703-56a70c1b1129-0', usage_metadata={'input_tokens': 113, 'output_tokens': 78, 'total_tokens': 191})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a parrot named Polly! Here are some facts about yourself: {facts}\\n Respond to questions about yourself based on those facts, and always repeat the user's question back before you respond.\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "question = \"What sport are you the best at?\"\n",
    "chain.invoke({\"question\": question, \"facts\": fake_db_retrieval()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "\n",
    "@traceable(run_type=\"retriever\")\n",
    "def fake_db_retrieval_step(question):\n",
    "    with open(\"../prompts/polly_facts.txt\", \"r\") as f:\n",
    "        poly_facts = f.read()\n",
    "    return {\"question\": question, \"facts\": poly_facts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get inputs for (question): got an unexpected keyword argument 'config'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You want to know which sport I'm the best at?\\n\\nWell, I think I'd say soccer! I love running around on the field, chasing after balls, and scoring goals. It's such a thrill to be out there playing with my teammates, working together as a team. Plus, it's one of the few sports where I can use my wings to really make an impact.\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-03-03T10:23:56.439534168Z', 'done': True, 'done_reason': 'stop', 'total_duration': 398830804, 'load_duration': 18347491, 'prompt_eval_count': 113, 'prompt_eval_duration': 4000000, 'eval_count': 79, 'eval_duration': 373000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-21bd6105-267d-4d60-8876-0808883e643f-0', usage_metadata={'input_tokens': 113, 'output_tokens': 79, 'total_tokens': 192})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a parrot named Polly! Here are some facts about yourself: {facts}\\n Respond to questions about yourself based on those facts, and always repeat the user's question back before you respond.\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = fake_db_retrieval_step | prompt | model\n",
    "\n",
    "question = \"What sport are you the best at?\"\n",
    "chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is an open-source project that aims to simplify the creation of blockchain- and web-based applications. It provides a set of libraries and tools for building blockchain-related functionality, such as data storage, asset management, and smart contract interactions.\n",
      "\n",
      "LangChain's main focus is on making it easier for developers to build decentralized applications (dApps) and integrate blockchain technology into their existing projects. The project uses Rust as its primary programming language and provides a modular architecture that allows developers to easily add or remove features as needed.\n",
      "\n",
      "Some of the key features of LangChain include:\n",
      "\n",
      "1. Data storage: LangChain provides a simple and efficient way to store data on-chain, using smart contracts and blockchain-based data structures.\n",
      "2. Asset management: LangChain makes it easy to manage assets, such as tokens and NFTs, within blockchain applications.\n",
      "3. Smart contract interactions: LangChain provides a set of libraries for interacting with smart contracts, making it easier to build dApps that rely on external contracts.\n",
      "4. Interoperability: LangChain aims to enable seamless interoperability between different blockchain platforms and protocols.\n",
      "\n",
      "Overall, LangChain is designed to make it easier for developers to build robust and scalable blockchain-based applications, while also providing a foundation for the development of decentralized applications (dApps).\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(\"What is LangChain?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao!', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-02-27T10:01:49.825681085Z', 'done': True, 'done_reason': 'stop', 'total_duration': 674177904, 'load_duration': 17835799, 'prompt_eval_count': 34, 'prompt_eval_duration': 5000000, 'eval_count': 4, 'eval_duration': 20000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-19f13669-bdf0-4f8e-89cb-ca2fe6c9cd46-0', usage_metadata={'input_tokens': 34, 'output_tokens': 4, 'total_tokens': 38})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
