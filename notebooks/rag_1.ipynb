{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c41f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_TRACING_v2\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"tutorial_chatbot\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c32e967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3402685b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import utils\n",
    "utils.tracing_is_enabled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b71623e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(model=\"qwen3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2940d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"qwen3\", model_provider=\"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "600c797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba272ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be72af62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 0\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf7ac25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19819b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 66 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a01c4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f2897ab7-fb0c-4bee-8c48-dea0dec8cd8f', '3255904b-5e95-4930-9448-4d7d28177792', '63d55efb-c7dd-4c0e-8262-3134d6b8aa15']\n"
     ]
    }
   ],
   "source": [
    "# Add documents to the vector store\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bc53c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ff82c3",
   "metadata": {},
   "source": [
    "## State:\n",
    "The state of our application controls what data is input to the application, transferred between steps, and output by the application. It is typically a TypedDict, but can also be a Pydantic BaseModel.\n",
    "\n",
    "For a simple RAG application, we can just keep track of the input question, retrieved context, and generated answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e3de258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d520651b",
   "metadata": {},
   "source": [
    "## Nodes (application steps)\n",
    "Let's start with a simple sequence of two steps: retrieval and generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c268281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6ea0b7",
   "metadata": {},
   "source": [
    "Our retrieval step simply runs a similarity search using the input question, and the generation step formats the retrieved context and original question into a prompt for the chat model.\n",
    "\n",
    "## Control flow\n",
    "Finally, we compile our application into a single graph object. In this case, we are just connecting the retrieval and generation steps into a single sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02f37b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c14d08a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38979eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [Document(id='63d55efb-c7dd-4c0e-8262-3134d6b8aa15', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='5043944a-05d6-42db-822d-a6bda67b4ae8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 19372}, page_content=\"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\"), Document(id='59a39aec-73ab-4c33-a51b-23222b1b3aa3', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='8b27fa46-d322-4866-8a6d-3346786b2adc', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17803}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.')]\n",
      "\n",
      "\n",
      "Answer: <think>\n",
      "Okay, the user is asking about Task Decomposition. Let me check the context provided.\n",
      "\n",
      "The context mentions that Task Decomposition is part of a LLM-powered agent system. It explains that complex tasks are broken down into smaller steps, and Chain of Thought (CoT) is a method used for this. CoT involves the model thinking step by step to decompose tasks. There's also mention of Tree of Thoughts extending CoT by exploring multiple reasoning paths. The answer should define Task Decomposition, mention CoT, and maybe note the extension with Tree of Thoughts. Need to keep it concise, three sentences max. Make sure to use the context details but not add extra info. Also, check if the answer needs to include the JSON parsing part, but the question is general, so probably not. Focus on the definition and methods mentioned.\n",
      "</think>\n",
      "\n",
      "Task Decomposition is the process of breaking down complex tasks into smaller, manageable steps. It leverages Chain of Thought (CoT) prompting to guide models in decomposing tasks systematically, enhancing performance on intricate problems. Techniques like Tree of Thoughts further expand this by exploring multiple reasoning paths through a tree structure.\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "\n",
    "print(f'Context: {result[\"context\"]}\\n\\n')\n",
    "print(f'Answer: {result[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "edb04d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieve': {'context': [Document(id='63d55efb-c7dd-4c0e-8262-3134d6b8aa15', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1585}, page_content='Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.'), Document(id='5043944a-05d6-42db-822d-a6bda67b4ae8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 19372}, page_content=\"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\"), Document(id='59a39aec-73ab-4c33-a51b-23222b1b3aa3', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2192}, page_content='Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'), Document(id='8b27fa46-d322-4866-8a6d-3346786b2adc', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17803}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': '<think>\\nOkay, the user is asking about Task Decomposition. Let me check the provided context.\\n\\nThe context mentions Task Decomposition in the section under Component One: Planning. It explains that complex tasks are broken into smaller steps. The Chain of Thought (CoT) method is highlighted as a standard technique where models \"think step by step\" to decompose tasks. Also, Tree of Thoughts extends CoT by exploring multiple reasoning paths. The answer should define Task Decomposition, mention CoT and Tree of Thoughts as methods, and note that it\\'s used to break down tasks into manageable parts. Keep it concise, three sentences max.\\n</think>\\n\\nTask Decomposition is the process of breaking down complex tasks into smaller, manageable steps. It often uses techniques like Chain of Thought (CoT) to guide models in decomposing problems systematically. Methods such as Tree of Thoughts further enhance this by exploring multiple reasoning paths during decomposition.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "764893e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>|\n",
      "|Okay|,| the| user| is| asking| about| Task| Decom|position|.| Let| me| check| the| provided| context|.\n",
      "\n",
      "|The| context| mentions| Task| Decom|position| as| part| of| a| L|LM|-powered| agent| system|.| It| explains| that| Co|T| (|Chain| of| Thought|)| is| a| method| where| the| model| breaks| down| complex| tasks| into| smaller| steps| by| thinking| step| by| step|.| Also|,| Tree| of| Thoughts| extends| this| by| exploring| multiple| reasoning| paths|.| The| answer| should| define| Task| Decom|position|,| mention| Co|T| and| Tree| of| Thoughts| as| methods|,| and| note| that| it|'s| used| to| simplify| complex| tasks|.| Need| to| keep| it| concise|,| three| sentences| max|.| Make| sure| to| use| the| context| provided| and| not| add| extra| info|.\n",
      "|</think>|\n",
      "\n",
      "|Task| Decom|position| is| the| process| of| breaking| down| complex| tasks| into| smaller|,| manageable| steps|.| It| lever|ages| methods| like| Chain| of| Thought| (|Co|T|)| and| Tree| of| Thoughts| to| guide| models| in| systematically| solving| problems| by| analyzing| dependencies| and| generating| sub|goals|.| This| approach| enhances| task| execution| efficiency| and| clar|ifies| the| model|'s| reasoning| process|.||"
     ]
    }
   ],
   "source": [
    "for message, metadata in graph.stream(\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"messages\"\n",
    "):\n",
    "    print(message.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f43cb66",
   "metadata": {},
   "source": [
    "## Query analysis\n",
    "So far, we are executing the retrieval using the raw input query. However, there are some advantages to allowing a model to generate the query for retrieval purposes. For example:\n",
    "\n",
    "In addition to semantic search, we can build in structured filters (e.g., \"Find documents since the year 2020.\");\n",
    "The model can rewrite user queries, which may be multifaceted or include irrelevant language, into more effective search queries.\n",
    "Query analysis employs models to transform or construct optimized search queries from raw user input. We can easily incorporate a query analysis step into our application. For illustrative purposes, let's add some metadata to the documents in our vector store. We will add some (contrived) sections to the document which we can filter on later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e31d914f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
       " 'start_index': 8,\n",
       " 'section': 'beginning'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_documents = len(all_splits)\n",
    "third = total_documents // 3\n",
    "\n",
    "for i, document in enumerate(all_splits):\n",
    "    if i < third:\n",
    "        document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "\n",
    "\n",
    "all_splits[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d04bee",
   "metadata": {},
   "source": [
    "We will need to update the documents in our vector store. We will use a simple InMemoryVectorStore for this, as we will use some of its specific features (i.e., metadata filtering). Refer to the vector store integration documentation for relevant features of your chosen vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "106a9027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "_ = vector_store.add_documents(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e3b1e6",
   "metadata": {},
   "source": [
    "Let's next define a schema for our search query. We will use structured output for this purpose. Here we define a query as containing a string query and a document section (either \"beginning\", \"middle\", or \"end\"), but this can be defined however you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d24ea8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"],\n",
    "        ...,\n",
    "        \"Section to query.\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7799ab",
   "metadata": {},
   "source": [
    "Finally, we add a step to our LangGraph application to generate a query from the user's raw input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ba3d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def analyze_query(state: State):\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    return {\"query\": query}\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b14d9f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c25533ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analyze_query': {'query': {'query': 'Task Decomposition', 'section': 'end'}}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'retrieve': {'context': [Document(id='944a3041-8900-4eb7-8a55-cac27faf1c45', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39220, 'section': 'end'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.'), Document(id='1eab390d-6516-4978-bb32-a9d227164f46', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 30951, 'section': 'end'}, page_content='Here are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",'), Document(id='cd318140-c982-4d03-93be-1c24592b0732', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 30187, 'section': 'end'}, page_content='You should only respond in JSON format as described below\\nResponse Format:\\n{\\n    \"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": \"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n}\\nEnsure the response can be parsed by Python json.loads\\nGPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",'), Document(id='35d43c51-d1c9-4984-9c56-96926834175a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39085, 'section': 'end'}, page_content='}\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': '<think>\\nOkay, let\\'s tackle this question. The user is asking what the end of the post says about Task Decomposition. First, I need to look through the provided context to find relevant information.\\n\\nThe context mentions \"Challenges in long-term planning and task decomposition\" and states that planning over a lengthy history and exploring solutions are challenging. It also says LLMs struggle to adjust plans with unexpected errors, making them less robust compared to humans. \\n\\nThe end of the post likely refers to these points. Task Decomposition is part of the challenges discussed, highlighting difficulties in breaking down tasks and adjusting plans. The answer should connect these points concisely. Since the user wants three sentences max, I\\'ll summarize the key challenge and the implication for LLMs.\\n</think>\\n\\nThe end of the post highlights challenges in task decomposition, noting difficulties in long-term planning and adjusting plans during unexpected errors. It emphasizes LLMs\\' struggle to robustly handle such scenarios compared to humans. Task decomposition remains a critical hurdle for effective solution exploration.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What does the end of the post say about Task Decomposition?\"},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0079476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import Annotated, List, TypedDict\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "# Update metadata (illustration purposes)\n",
    "total_documents = len(all_splits)\n",
    "third = total_documents // 3\n",
    "\n",
    "for i, document in enumerate(all_splits):\n",
    "    if i < third:\n",
    "        document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "\n",
    "\n",
    "# Index chunks\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "_ = vector_store.add_documents(all_splits)\n",
    "\n",
    "\n",
    "# Define schema for search\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"],\n",
    "        ...,\n",
    "        \"Section to query.\",\n",
    "    ]\n",
    "\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def analyze_query(state: State):\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    return {\"query\": query}\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "779f7435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analyze_query': {'query': {'query': 'Task Decomposition', 'section': 'end'}}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'retrieve': {'context': [Document(id='49423c91-8173-4683-b916-f09841f2ec72', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'end'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.'), Document(id='78c77137-5a96-47cf-82ab-5b5606d8efee', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'end'}, page_content='Here are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",'), Document(id='a3b62e47-258f-4da4-8057-16b7e813ef2a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'end'}, page_content='You should only respond in JSON format as described below\\nResponse Format:\\n{\\n    \"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": \"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n}\\nEnsure the response can be parsed by Python json.loads\\nGPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",'), Document(id='e79a4be9-2465-41e9-82b6-748102f8c190', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'section': 'end'}, page_content='}\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': '<think>\\nOkay, let\\'s tackle this question. The user is asking what the end of the post says about Task Decomposition. First, I need to look through the provided context to find relevant information.\\n\\nThe context mentions \"Challenges in long-term planning and task decomposition\" and states that planning over a lengthy history and exploring the solution space are challenging. It also says LLMs struggle to adjust plans when there are unexpected errors, making them less robust compared to humans. \\n\\nThe user is specifically asking about the end of the post, so I should check if the last part of the context discusses Task Decomposition. The last paragraph talks about GPT-Engineer\\'s approach, where the model breaks down tasks into smaller components and asks for user clarification. This seems related to task decomposition. \\n\\nPutting it together, the answer should mention that the end of the post discusses task decomposition as part of the challenges, noting that LLMs have difficulty adjusting plans and that GPT-Engineer uses decomposition with user input. Need to keep it concise, three sentences max.\\n</think>\\n\\nThe end of the post highlights challenges in task decomposition, noting LLMs struggle to adjust plans during unexpected errors, reducing robustness. It mentions GPT-Engineer\\'s approach of breaking tasks into smaller components and seeking user clarification for precision. Task decomposition remains critical for handling complex, long-term planning scenarios.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What does the end of the post say about Task Decomposition?\"},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5357070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document(s)\n",
      "Total characters: 10473\n",
      "/\n",
      "\n",
      "Glossary\n",
      "\n",
      "Glossary of openBIS/Data Store terms\n",
      "\n",
      "¶ Collection\n",
      "\n",
      "In openBIS, a Collection is a folder with user-defined Properties located on the third level of the hierarchical data structure (Space/Project/Collection/Object). A Collection is always part of a Project. Collections of the same type are described by the same set of Properties. Collection types are defined as part of the openBIS masterdata. Datasets can be attached to Collections. A Collection can logically group an unlimited number of Object of one or more Object types. For instance, a Collection of the type \"Measurement Devices\" can be used to organize Objects of the type \"Instrument\" in the Inventory. A Collection of the type \"Default Experiment\" can be used to organize Objects of the type \"Experimental Step\" in the Lab Notebook.\n",
      "\n",
      "uml diagram\n",
      "\n",
      "¶ Controlled Vocabulary\n",
      "\n",
      "A controlled vocabulary is an established list of terms to provide consistency and uniqueness in the description of a given domain, e.g., a list of room labels, SI units or purity grades. In openBIS, controlled vocabularies are a possible data type for metadata Properties. Each term in a controlled vocabulary has a code, a label, and a description. All existing controlled vocabularies and their terms are listed in the Vocabulary Browser in the Utilities.\n",
      "\n",
      "¶ Dataset\n",
      "\n",
      "In openBIS, a Dataset is a folder with user-defined Properties that can contain individual files of arbitrary formats (e.g., images, csv files, xml files, etc.) as well as complex folder structures with subfolders and many files (of potentially different formats). The content of Datasets (but not their metadata) is immutable, i.e., it cannot be edited after creation. Datasets of the same type are described by the same set of Properties. Dataset types are defined as part of the openBIS masterdata. A Dataset has to be attached to either an Object or to a Collection. Different Datasets can be connected via parent-child relationships.\n",
      "\n",
      "uml diagram\n",
      "\n",
      "¶ Dropbox\n",
      "\n",
      "The Dropbox is a core openBIS plugin that allows the upload of (large) data files to an openBIS instance. Instead of using the user interface for Dataset registration, users move their data files (+ information about the Object or Collection they should be attached to) to a dedicated Dropbox folder in a file-service at BAM that is continously monitored. Once new data files are detected inside the Dropbox folder, they are automatically uploaded as Datasets to the openBIS instance. It is possible to control the Dataset registration process via Dropbox scripts written in Python. The script can register new Datasets, Objects, Properties and parent-child relationships as part of its processing. The Dropbox framework also provides tools to track file operations and, if necessary, revert them, ensuring that the incoming file or directory is returned to its original state in the event of an error. The Dropbox is not related to the commercial file hosting service.\n",
      "\n",
      "¶ Entity Types\n",
      "\n",
      "An Entity is an item of the \"real world\" (tangible/non tangible) that is uniquely identified by attributes (properties). An Entity Type is a collection of Entities with similar properties. An Entity Type is an object in a data model. In openBIS relevant entity types are Collection, Object and Dataset types. Entity types can only be created by someone with the Instance admin role.\n",
      "\n",
      "¶ Inventory\n",
      "\n",
      "The Inventory is one of the two main components of openBIS. It is used for the digital representation of shared laboratory inventory and the storage of related data files such as measuring instruments, chemical substances, and samples, but can also be user for storing protocols, standard operating procedures (SOPs) and publications. The Inventory is organized into Spaces, Projects and Collections according to the hierarchical data structure of openBIS.\n",
      "\n",
      "By default, each BAM division gets\n",
      "\n",
      "closed Inventory Spaces (Equipment, Materials, Methods, Publications) that are only accessible to division members\n",
      "\n",
      "open Inventory Projects (Equipment, Materials, Methods) that are accessible to every user of the Data Store.\n",
      "\n",
      "¶ Jupyter Notebook\n",
      "\n",
      "Jupyter Notebook is a web-based interactive computing platform that combines live code, equations, narrative text, visualizations, interactive dashboards and other media. Jupyter Notebooks can be used to analyze data stored in an openBIS instance.\n",
      "\n",
      "¶ Lab Notebook\n",
      "\n",
      "The Lab Notebook is one of the two main components of openBIS. It is the digital version of a paper lab notebook and can be used for the digital representation and documentation of experimental procedures and analyses and the storage of related data files according to good scientific practice. By default, each user gets their own personal Space in the Lab Notebook where they can represent multiple research Projects. Within a given Project, Collections can be used to represent comprehensive experiments which comprise individual Objects, e.g., of the type \"Experimental Step\". Access to the personal Lab Notebook Space or individual Projects can be shared with colleagues.\n",
      "\n",
      "uml diagram\n",
      "\n",
      "¶ Masterdata\n",
      "\n",
      "The term \"masterdata\" describes all information structures and plugins that are used to define metadata in openBIS (i.e., masterdata = \"meta-metadata\"). Masterdata is comprised of entity types, i.e., Collection, Object and Dataset types, as well as Property types, controlled vocabularies and related scripts (e.g., dynamic property plugins and entity validation scripts). Domain-specific masterdata have to be defined by the Data Store Stewards of the BAM divisions, but can only be imported to the openBIS instance (and edited) by Instance Admins.\n",
      "\n",
      "¶ Object\n",
      "\n",
      "In openBIS, an Object is an entity with user-defined Properties located on the fourth level of the hierarchical data structure (Space/Project/Collection/Object). An Object is always part of a Collection. Objects of the same type are described by the same set of Properties. Object types are defined as part of the openBIS masterdata. Datasets can be attached to Objects. An Object can be used to represent any kind of physical or intangible entity. For instance, an Object of the type \"Chemical\" can be used to represent a batch of ethanol in the Inventory. An Object of the type \"Experimental Step\" can be used to represent a measurement or an analysis in the Lab Notebook.\n",
      "\n",
      "uml diagram\n",
      "\n",
      "¶ Parent-Child Relationship\n",
      "\n",
      "A parent-child relationship is a directed link (or \"directed edge\" in graph theory) between two Objects (Object1 --> Object2) or between two Datasets (Dataset1 --> Dataset2) in an openBIS Instance. For a given relationship between two Objects (or Datasets), the Object with the outgoing edge is called the \"parent\" and the Object with the incoming edge is called the \"child\". It is not possible to have parent-child relationships between Objects and Datsets or between other entity types (e.g., Collection).\n",
      "\n",
      "Parent-child relationships can be used to represent different kinds of logical connections between Objects (or Datasets), e.g.:\n",
      "\n",
      "a partition of an entity: Object \"Sample 1\" is parent of Objects \"Sample 1A\" and \"Sample 1B\" because the original sample was broken up into two smaller sub-samples,\n",
      "\n",
      "uml diagram\n",
      "\n",
      "context in a research process, e.g., Object \"Experimental Step 1\" is child of the Objects \"Sample 1A\" and \"Measurement Device 1\" because during the experimental step, the measurement device was used to measure some properties of the sub-sample,\n",
      "\n",
      "uml diagram\n",
      "\n",
      "a temporal sequence of different steps in a workflow: Object \"Experimental_Step_1\" is parent of \"Experimental Step 2\" because the first experimental step was conducted prior to the second.\n",
      "\n",
      "uml diagram\n",
      "\n",
      "When all of these Objects and their connections to each other are combined, we get a hierarchy tree (or a \"directed acyclic graph\" (DAG) in graph theory):\n",
      "\n",
      "uml diagram\n",
      "\n",
      "Parent-child relationships are not allowed to form cycles within the graph (e.g., an Object cannot be both parent and child of another Object), otherwise an error will be reported.\n",
      "\n",
      "Parent-child relationship can also be used to represent relations between Datasets, e.g., \"Dataset_v2\" being the parent of \"Dataset_v1\" because the second Dataset is a newer version of the first one.\n",
      "\n",
      "Parent-child relationships between Objects (or Datasets) are independent of the folder hierarchy, i.e., Objects (or Datasets) can be connected across different Spaces and Projects and irrespective of whether they are located in the Inventory or the Lab Notebook. By default, every Object (or Dataset) can have a unlimited number of parents and/or children or none (N:N relationships with N being any number from 0 to N). For a given Object type, group admins can set a minimum and maximum number of children and parents of a certain type in the settings.\n",
      "\n",
      "¶ Project\n",
      "\n",
      "In openBIS, a Project is a folder located on the second level of the hierarchical data structure (Space/Project/Collection/Object). A Project is always part of a Space. A Project can logically group an unlimited number of Collections. For instance, a Project \"Reagents\" can be used to organize Collections of the type \"Chemicals\" in the Inventory. A Project \"Master Thesis\" can be used to organize Collections of the type \"Experiment\" in the Lab Notebook. Apart from a code (PermId) and a description, Projects have no metadata. User access rights can be defined at the Project-level.\n",
      "\n",
      "uml diagram\n",
      "\n",
      "¶ Property\n",
      "\n",
      "In openBIS, a Property is a metadata field that can be used to describe a Collection, an Object or a Dataset. Properties can be of different data types, e.g., numbers (Boolean, real, integer), text, hyperlink, date, controlled vocabularies but also tabular data.\n",
      "\n",
      "¶ pyBIS\n",
      "\n",
      "pyBIS is a Python module for interacting with openBIS. Most actions that can be carried out in the openBIS graphical user interface (GUI) can also be done via pyBIS. pyBIS is designed to be most useful in a Jupyter Notebook or IPython environment.\n",
      "\n",
      "¶ Space\n",
      "\n",
      "In openBIS, a Space is a folder located on the first level of the hierarchical data structure (Space/Project/Collection/Object). A Space is either located in the Inventory or in the Lab Notebook. A Space can logically group an unlimited number of Projects. For instance, a Space \"Materials\" can include the Project \"Reagents\" in the Inventory. A Space \"Master Students\" can include the Project \"Master Thesis\" in the Lab Notebook. Apart from the permanent ID (PermId) and a description, Spaces have no metadata. User access rights can be defined at the Space-level.\n",
      "\n",
      "uml diagram\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import SeleniumURLLoader\n",
    "\n",
    "loader = SeleniumURLLoader(urls=[\"https://datastore.bam.de/en/Glossary\"])\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(docs)} document(s)\")\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")\n",
    "print(docs[0].page_content[:10473])  # preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "670b32c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 14 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc77f19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0e327562-c509-484b-bed4-a07cec65b395', '6c2d213a-49af-404d-ac02-4873c643e522', '57e60334-9468-4727-a36d-ea881b53b06a']\n"
     ]
    }
   ],
   "source": [
    "# Add documents to the vector store\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52ee064a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ae66c4",
   "metadata": {},
   "source": [
    "## State:\n",
    "The state of our application controls what data is input to the application, transferred between steps, and output by the application. It is typically a TypedDict, but can also be a Pydantic BaseModel.\n",
    "\n",
    "For a simple RAG application, we can just keep track of the input question, retrieved context, and generated answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73329476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70180aab",
   "metadata": {},
   "source": [
    "## Nodes (application steps)\n",
    "Let's start with a simple sequence of two steps: retrieval and generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22520cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61d7f59",
   "metadata": {},
   "source": [
    "Our retrieval step simply runs a similarity search using the input question, and the generation step formats the retrieved context and original question into a prompt for the chat model.\n",
    "\n",
    "## Control flow\n",
    "Finally, we compile our application into a single graph object. In this case, we are just connecting the retrieval and generation steps into a single sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53c5c43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37f4ee17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d3a6533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [Document(id='1f1ba6a4-d431-4e7b-8a72-ed073f64ab79', metadata={'source': 'https://datastore.bam.de/en/Glossary', 'title': 'Glossary of openBIS/Data Store terms | Data Store - FDM@BAM', 'description': 'No description found.', 'language': 'en', 'start_index': 9628}, page_content='¶ pyBIS\\n\\npyBIS is a Python module for interacting with openBIS. Most actions that can be carried out in the openBIS graphical user interface (GUI) can also be done via pyBIS. pyBIS is designed to be most useful in a Jupyter Notebook or IPython environment.\\n\\n¶ Space\\n\\nIn openBIS, a Space is a folder located on the first level of the hierarchical data structure (Space/Project/Collection/Object). A Space is either located in the Inventory or in the Lab Notebook. A Space can logically group an unlimited number of Projects. For instance, a Space \"Materials\" can include the Project \"Reagents\" in the Inventory. A Space \"Master Students\" can include the Project \"Master Thesis\" in the Lab Notebook. Apart from the permanent ID (PermId) and a description, Spaces have no metadata. User access rights can be defined at the Space-level.\\n\\numl diagram'), Document(id='26260fc7-343e-4c7a-9e58-cef024da66e1', metadata={'source': 'https://datastore.bam.de/en/Glossary', 'title': 'Glossary of openBIS/Data Store terms | Data Store - FDM@BAM', 'description': 'No description found.', 'language': 'en', 'section': 'end'}, page_content='¶ pyBIS\\n\\npyBIS is a Python module for interacting with openBIS. Most actions that can be carried out in the openBIS graphical user interface (GUI) can also be done via pyBIS. pyBIS is designed to be most useful in a Jupyter Notebook or IPython environment.\\n\\n¶ Space\\n\\nIn openBIS, a Space is a folder located on the first level of the hierarchical data structure (Space/Project/Collection/Object). A Space is either located in the Inventory or in the Lab Notebook. A Space can logically group an unlimited number of Projects. For instance, a Space \"Materials\" can include the Project \"Reagents\" in the Inventory. A Space \"Master Students\" can include the Project \"Master Thesis\" in the Lab Notebook. Apart from the permanent ID (PermId) and a description, Spaces have no metadata. User access rights can be defined at the Space-level.\\n\\numl diagram'), Document(id='9f94ba1a-9229-40ba-bd83-2463b09b3658', metadata={'source': 'https://datastore.bam.de/en/Glossary', 'title': 'Glossary of openBIS/Data Store terms | Data Store - FDM@BAM', 'description': 'No description found.', 'language': 'en', 'section': 'end'}, page_content='¶ Project\\n\\nIn openBIS, a Project is a folder located on the second level of the hierarchical data structure (Space/Project/Collection/Object). A Project is always part of a Space. A Project can logically group an unlimited number of Collections. For instance, a Project \"Reagents\" can be used to organize Collections of the type \"Chemicals\" in the Inventory. A Project \"Master Thesis\" can be used to organize Collections of the type \"Experiment\" in the Lab Notebook. Apart from a code (PermId) and a description, Projects have no metadata. User access rights can be defined at the Project-level.\\n\\numl diagram\\n\\n¶ Property\\n\\nIn openBIS, a Property is a metadata field that can be used to describe a Collection, an Object or a Dataset. Properties can be of different data types, e.g., numbers (Boolean, real, integer), text, hyperlink, date, controlled vocabularies but also tabular data.\\n\\n¶ pyBIS'), Document(id='21111655-9806-4da4-a4e5-304cae07f443', metadata={'source': 'https://datastore.bam.de/en/Glossary', 'title': 'Glossary of openBIS/Data Store terms | Data Store - FDM@BAM', 'description': 'No description found.', 'language': 'en', 'start_index': 8742}, page_content='¶ Project\\n\\nIn openBIS, a Project is a folder located on the second level of the hierarchical data structure (Space/Project/Collection/Object). A Project is always part of a Space. A Project can logically group an unlimited number of Collections. For instance, a Project \"Reagents\" can be used to organize Collections of the type \"Chemicals\" in the Inventory. A Project \"Master Thesis\" can be used to organize Collections of the type \"Experiment\" in the Lab Notebook. Apart from a code (PermId) and a description, Projects have no metadata. User access rights can be defined at the Project-level.\\n\\numl diagram\\n\\n¶ Property\\n\\nIn openBIS, a Property is a metadata field that can be used to describe a Collection, an Object or a Dataset. Properties can be of different data types, e.g., numbers (Boolean, real, integer), text, hyperlink, date, controlled vocabularies but also tabular data.\\n\\n¶ pyBIS')]\n",
      "\n",
      "\n",
      "Answer: <think>\n",
      "Okay, the user is asking what the web says about pyBIS. Let me look at the provided context.\n",
      "\n",
      "The context mentions that pyBIS is a Python module for interacting with openBIS. It allows most actions done in the GUI to be performed via pyBIS, especially useful in Jupyter Notebooks or IPython. There's also info about Spaces, Projects, and Properties in openBIS, but the user specifically asked about pyBIS. \n",
      "\n",
      "I need to keep the answer concise, three sentences max. So first sentence: pyBIS is a Python module for openBIS interaction. Second: It replicates GUI actions and works well with Jupyter/IPython. Third: It's part of openBIS's hierarchical structure, but maybe that's more about the system. Wait, the third point might be about the Spaces, Projects, etc., but the user asked about pyBIS. So maybe the third sentence can mention that it's used within the openBIS framework. Let me check the context again. The context repeats the pyBIS description, so the answer should focus on pyBIS's purpose and usage. The third sentence could mention the environments it's designed for. Let me structure that.\n",
      "</think>\n",
      "\n",
      "pyBIS is a Python module for interacting with openBIS, enabling most GUI actions through code. It is optimized for use in Jupyter Notebooks or IPython environments. The tool facilitates managing openBIS's hierarchical data structure, including Spaces, Projects, and Properties.\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\"question\": \"What does the web says about pyBIS?\"})\n",
    "\n",
    "print(f'Context: {result[\"context\"]}\\n\\n')\n",
    "print(f'Answer: {result[\"answer\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2aa8973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader, SeleniumURLLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import Annotated, List, TypedDict\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = SeleniumURLLoader(urls=[\"https://datastore.bam.de/en/Glossary\"])\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "# Update metadata (illustration purposes)\n",
    "total_documents = len(all_splits)\n",
    "third = total_documents // 3\n",
    "\n",
    "for i, document in enumerate(all_splits):\n",
    "    if i < third:\n",
    "        document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "\n",
    "\n",
    "# Index chunks\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "_ = vector_store.add_documents(all_splits)\n",
    "\n",
    "\n",
    "# Define schema for search\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"],\n",
    "        ...,\n",
    "        \"Section to query.\",\n",
    "    ]\n",
    "\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def analyze_query(state: State):\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    return {\"query\": query}\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb11fbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analyze_query': {'query': {'query': 'Parent-Child Relationship', 'section': 'Middle'}}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'retrieve': {'context': []}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': \"<think>\\nOkay, the user is asking about the middle of the post regarding the Parent-Child Relationship. Let me check the context provided. Wait, the context here is empty. The user probably forgot to include the actual content they want me to reference. Since there's no context given, I can't extract any information. I should inform them that the context is missing. Let me make sure I don't make up any details. Just a straightforward response that I don't have the necessary information. Keep it concise, three sentences max. Alright, that's done.\\n</think>\\n\\nThe context provided is empty, so I cannot answer the question about the middle of the post. Please provide the relevant content for an accurate response.\"}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What does the middle of the post say about Parent-Child Relationship?\"},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
