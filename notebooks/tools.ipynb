{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d742bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_TRACING_v2\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"tutorial\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "234d35b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65153660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import utils\n",
    "utils.tracing_is_enabled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fd5e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(model=os.getenv(\"LLM_MODEL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6e5085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "llm_with_tools = model.bind_tools([multiply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b66289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm_with_tools.invoke(\"What is 2 multiplied by 3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "966e6160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 2, 'b': 3},\n",
       "  'id': '94fad2a0-9978-416b-a412-9ca72f80f348',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ac03878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-04-17T14:46:03.352120841Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4233483567, 'load_duration': 3778663313, 'prompt_eval_count': 187, 'prompt_eval_duration': 130000000, 'eval_count': 22, 'eval_duration': 322000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-c9a44fc0-2aaa-4930-8277-8621d37ed4c4-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': '94fad2a0-9978-416b-a412-9ca72f80f348', 'type': 'tool_call'}], usage_metadata={'input_tokens': 187, 'output_tokens': 22, 'total_tokens': 209})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06ff250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]\n",
    "\n",
    "llm_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07878fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'e6b7ecfe-83b7-4521-ab86-1a0d9383278d', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': '86819db4-88b7-4b44-b13a-02104beb4a12', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(ai_msg.tool_calls)\n",
    "\n",
    "messages.append(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47a26bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-04-17T14:50:18.322003455Z', 'done': True, 'done_reason': 'stop', 'total_duration': 666838547, 'load_duration': 18874800, 'prompt_eval_count': 231, 'prompt_eval_duration': 13000000, 'eval_count': 44, 'eval_duration': 633000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-daca7adf-67a9-4d57-b23e-c79ba3492c93-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'e6b7ecfe-83b7-4521-ab86-1a0d9383278d', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': '86819db4-88b7-4b44-b13a-02104beb4a12', 'type': 'tool_call'}], usage_metadata={'input_tokens': 231, 'output_tokens': 44, 'total_tokens': 275}),\n",
       " ToolMessage(content='36', name='multiply', tool_call_id='e6b7ecfe-83b7-4521-ab86-1a0d9383278d'),\n",
       " ToolMessage(content='60', name='add', tool_call_id='86819db4-88b7-4b44-b13a-02104beb4a12')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3d5e97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result from the multiply operation is: 36\n",
      "The result from the add operation is: 60\n"
     ]
    }
   ],
   "source": [
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "# Invoke the LLM with tool use\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "# Process each tool call\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    operation = tool_call[\"name\"].lower()\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[operation]\n",
    "    \n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    \n",
    "    # Print result in a human-readable way\n",
    "    print(f\"The result from the {operation} operation is: {tool_msg.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d5bc0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of 3 * 12 is 36.\n",
      "\n",
      "The result of 11 + 49 is 60.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "# First, ask the model\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "\n",
    "# Collect tool responses\n",
    "tool_responses = []\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    operation = tool_call[\"name\"].lower()\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[operation]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    tool_responses.append(tool_msg)\n",
    "\n",
    "# Append original AI message + tool responses\n",
    "messages.append(ai_msg)\n",
    "messages.extend(tool_responses)\n",
    "\n",
    "# Let the model now \"wrap it up\" in a human-friendly answer\n",
    "final_response = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(final_response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
